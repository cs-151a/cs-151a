# CSE-151A

Link to Jupyter Notebook: [https://github.com/cs-151a/cs-151a/blob/main/stocks.ipynb](https://github.com/cs-151a/cs-151a/blob/main/stocks.ipynb)

### Milestone 2 - Explanation of Dataset Preprocessing:
**1. Change format of 'Date' column**
* The current 'Date' column is in object format (ex. 2018-11-29 00:00:00-05:00). This is not ideal for the time-series analysis we wish to perform on the data. So, we will convert to a datetime format, allowing for more convenient month and year extraction as well as time-based indexing. Additionally, we will drop the time from this column entirely, as we simply need the date and year for each company's stock entries.

**2. Sort each company's data by Date**
* To assist in the time-series analysis mentioned in Step 1, we will put each company's data in sequential order based on 'Date' data. Since we have 5 years worth of data, as well as data for each day the market is open, sorting each company's data sequentially will be crucial in keeping our dataset organized and efficiently readable.

**3. Handle duplicate data**
* If for some reason a company has multiple data entries for the same date in the 'Date' column, we will remove any extraneous entries because they are not necessary for training the model. On top of that, the model can become confused if it encounters more than or less than 491 entries for the same date, so we need to make sure each date contains solely 491 entries as we have exactly 491 ticker symbols.

**4. Encode categorical data**
* We cannot build our model on non-numerical data values, so we will need to encode any such instances in our dataset. Particularly, the 'Company' column contains strings for each company's stock symbol, so we will use one-hot encoding to convert them to numerical data. For instance, consider the company symbols 'AAPL', 'MSFT', and 'TSLA'. By one-hot encoding these values, we would make a row with three new columns similar to this: ('Company_AAPL', 'Company_MSFT', 'Company_TSLA'). However, they will be filled with zeros, and only a singular one to represent a specific company. For instance, AAPL would be (1, 0, 0) whereas TSLA would be (0, 0, 1) in our sample case. 

**5. Drop unnecessary columns**
* We can drop the 'Dividends' and 'Stock Splits' columns because these data are not necessary in building our model. This is due to the fact that our model will be focused on calculating predicted risk-adjusted return, sharpe ratios, as well as volatility, none of which require dividens or stock splits to calculate. Not only that, but it's not fair to consider these data columns in training our model because there exist companies that don't partake in dividends or stock splits despite generating lots of returns. Thus, dropping them will reduce potential confusion and better streamline the process of training our model. 

**6. Predicted Risk-Adjusted Return**
* Calculates and ranks the performance of stocks based on their risk-adjusted return. It begins by converting the Date column to a datetime format and sorting the data by Company and Date. Using grouped calculations for each company, it computes daily returns, annualized return (mean of daily returns scaled to a year), annualized volatility (standard deviation of daily returns scaled to a year), and the risk-adjusted return (annualized return divided by annualized volatility). These metrics are compiled into a results DataFrame. The results are then ranked by Risk-Adjusted Return in descending order, with a Rank column added for clarity. The output shows which stocks offer the best return relative to risk.

### Milestone 3 - Dataset Preprocessing Step:
All our new work and updates that we have made for Milestone 3 can be found in our Jupyter Notebook (See link above). We finished preprocessing, introduced three new features (Risk-adjusted return, Sharpe Ratio, and Volatility), and trained and evaluated our very first model to comply with the instructions given. 

**1. Where does your model fit in the fitting graph?**
* The current model we're using is a RandomForestRegressor. This model functions by taking the average of multiple decision trees in order to reduce variance. This generally helps to reduce overfitting while still being able to captue complicated data patterns. To evaluate where the model fits in the fitting graph, we must compare the actual vs. predicted values, as are graphed in the evaluation of our model. If the model is performing well, most points will be close to the diagonal line, where predicted values match the actual values. A large concentration of points near this line suggests that the model is making accurate predictions and fits the data well. In our case, the actual vs. predicted values appear close to the diagonal, indicating that the model performs well, with a good balance of accuracy and generalization. This shows that the RandomForestRegressor fits well in the fitting graph, as it is effectively capturing the underlying patterns without significant overfitting or underfitting.

**2. What are the next models you are thinking of and why?**
* It's clear that our current MSE and MAE values are very low (0.000 and 0.0030, respectively). Given these two statistics alone, we can conclude that our model is making strong, accurate predictions for the most part. Accordingly, it's not entirely necessary to evaluate different models because it seems we have already hit the sweet spot. However, other statistics we gathered may lead us use different models that can perform similarly with less complexity. For example, our R^2 value is very high (0.9167), which means that the model is able to account for most of the variance in the target variable of the model. This means that we could possibly produce similar predictions by way of a Linear Regression model, while also giving us more interpretability of the model results. Not only that, but we can also utilize a Support Vector Regression model in order to capture possible non-linear relationships between our stock price prediction. This would be a little more complex however, as this type of model works best on smaller datasets, requiring us to further preprocess data into smaller, select stock groups.

**3. What is the conclusion of your 1st model?**
* Our first model demonstrated promising predictive capabilities with a high R-squared value of 0.9463 and minimal mean squared error in stock performance forecasting. However this level of accuracy raises concerns about potential overfitting in our model. While implementing additional features like volume trends provided supplementary data points, we realize these may have introduced unnecessary noise into our core metrics. Our weighting methodology, particularly in the 50/30/20 feature split implementation, lacked the mathematical rigor typically expected in quantitative finance models.

**4. What can be done to possibly improve it?**
* We can improve our model's performance with the following. Implementing proper feature-level weight distribution, introducing cross-validation mechanisms to address overfitting concerns, and integrating more sophisticated risk metrics for robust performance evaluation. Also expanding our dataset to incorporate longer time series data and relevant macroeconomic indicators would enhance our model's predictive capabilities. We could also implement more rigorous backtesting protocols and consider tiny market effects to better simulate real world trading conditions. These optimizations can be implemented in our model's later iterations to demonstrate significant improvements in the performance.
